import urllib.request, re, html
def links():
    f = open('статьи.csv', 'r', encoding = 'UTF-8')
    link = []
    for m in f:
        link.append(m)
    f.close()
    return link
    
def reg(link):
    filer = ['<p>(.*?)</em></p>',
             '<p><strong>(.*?)</p>\n <div class=',
             '<p><strong>(.*?)</p>\n<p><strong>',
             '<span class="_ga1_on_ include-relap-widget contextualizable">(.*?)</span>']
    tex = []
    for i,url in enumerate(link): 
        page = urllib.request.urlopen(url) 
        try: 
            htl = page.read().decode('utf-8') 
        except: 
            htl = page.read().decode('windows-1251')
        r = re.compile(filer[i], flags=re.U | re.DOTALL)
        regex = re.search(r,htl)
        if regex:
            n = regex.group(1)
            regTag = re.compile('<.*?>', flags=re.U | re.DOTALL)            
            regSpace = re.compile('\s', flags=re.U | re.DOTALL)
            n = regTag.sub(' ', html.unescape(n))
            n = regSpace.sub(' ', n)
            tex.append(n)
            print (tex)
            return tex
         
def words_sets(tex):
    sets = []
    for elem in tex:
        sets.append(set(elem))
    return sets

def words(tex):
    d = {}
    for line in tex:
        for word in line:
            if word in d:
                d[word] += 1
            else:
                d[word] = 1
    print(d)
    return d

def main():
    a = links()
    b = reg(a)
    c = words_sets(b)
    d = words(b)
if __name__ == '__main__':
    main()

